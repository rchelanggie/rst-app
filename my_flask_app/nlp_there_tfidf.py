# -*- coding: utf-8 -*-
"""Copy of NLP THERE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UY74yHRMwcniXm7vOyAY1MhSnnJKlYjA

# TF-IDF
"""

import pandas as pd

# Masukkan URL yang dibagikan di sini
# url = 'https://drive.google.com/uc?id=1yOepW6tQ0SeetNguQFKFPuV5Qxrqs2wZ'

# ini rekap
url = 'https://drive.google.com/uc?id=1e09AIZZBf7Ljt0BUJSUBEoQ9NgLX29Gz' 

# Memuat dataset CSV ke dalam DataFrame
df = pd.read_csv(url)

# Tampilkan beberapa baris pertama dari DataFrame
print(df.head())

df['Body'] = df['Body'].str.lower()
print(df['Body'])

import pandas as pd
import re
import string
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

# Langkah 1: Mengimpor pustaka yang diperlukan
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# Langkah 3: Menghapus nilai yang hilang (missing values)
df.dropna(subset=['Body'], inplace=True)

# Langkah 4: Case folding
df['Body'] = df['Body'].str.lower()

# Langkah 5: Menghapus tanda baca
def remove_punctuation(text):
    return text.translate(str.maketrans('', '', string.punctuation))

df['Body'] = df['Body'].apply(remove_punctuation)

# Langkah 6: Menghapus angka
df['Body'] = df['Body'].str.replace('\d+', '')

# Langkah 7: Menghapus stop words
stop_words = set(stopwords.words('english'))

def remove_stopwords(text):
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if word not in stop_words]
    return ' '.join(filtered_text)

df['Body'] = df['Body'].apply(remove_stopwords)

# Langkah 8: Stemming
ps = PorterStemmer()

def stemming(text):
    word_tokens = word_tokenize(text)
    stemmed_text = [ps.stem(word) for word in word_tokens]
    return ' '.join(stemmed_text)

df['Body'] = df['Body'].apply(stemming)

# Langkah 9: Lemmatization (opsional)
lemmatizer = WordNetLemmatizer()

def lemmatize(text):
    word_tokens = word_tokenize(text)
    lemmatized_text = [lemmatizer.lemmatize(word) for word in word_tokens]
    return ' '.join(lemmatized_text)

df['Body'] = df['Body'].apply(lemmatize)

# Menampilkan beberapa baris pertama dari DataFrame yang telah diproses
print(df.head())

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

# Menggunakan TF-IDF untuk ekstraksi fitur
vectorizer = TfidfVectorizer(max_features=5000)  # Anda dapat mengatur jumlah fitur sesuai kebutuhan

# Mengubah teks menjadi fitur TF-IDF
X = vectorizer.fit_transform(df['Body'])
y = np.array(df['Sentiment'])
# y = df['Label']

# Melihat ukuran matriks fitur
print(X.shape)

# from sklearn.datasets import load_iris
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import SGDClassifier
# from sklearn.metrics import accuracy_score, classification_report


# # Membagi dataset menjadi data latih dan data uji
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Melatih model SGD
# sgd_model = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)
# sgd_model.fit(X_train, y_train)

# # Memprediksi sentimen pada data uji
# y_pred = sgd_model.predict(X_test)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report
import numpy as np

random_states = [0, 1, 2, 42, 100]
results = []

for rs in random_states:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)

    sgd_model = SGDClassifier(loss="hinge", penalty="l2", max_iter=1000)
    sgd_model.fit(X_train, y_train)

    y_pred = sgd_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results.append((rs, accuracy))

# Print the results
for rs, acc in results:
    print(f"Random state: {rs}, Accuracy: {acc:.4f}")

best_random_state = 2

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=best_random_state)

sgd_model = SGDClassifier(loss="hinge", penalty="l2", max_iter=1000)
sgd_model.fit(X_train, y_train)

y_pred = sgd_model.predict(X_test)

# Menghitung akurasi model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

# Menampilkan laporan klasifikasi dengan parameter zero_division
print(classification_report(y_test, y_pred, zero_division=0))